apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: open-vaccine-
  annotations: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.2, pipelines.kubeflow.org/pipeline_compilation_time: '2022-03-09T08:28:11.813599',
    pipelines.kubeflow.org/pipeline_spec: '{"description": "ML model for the open
      vaccine Kaggle competition", "inputs": [{"default": "64", "name": "BATCH_SIZE",
      "optional": true}, {"default": "0.5", "name": "DROPOUT", "optional": true},
      {"default": "100", "name": "EMBED_DIM", "optional": true}, {"default": "10",
      "name": "EPOCHS", "optional": true}, {"default": "128", "name": "HIDDEN_DIM",
      "optional": true}, {"default": "0.001", "name": "LR", "optional": true}, {"default":
      "0.3", "name": "SP_DROPOUT", "optional": true}, {"default": "107", "name": "TRAIN_SEQUENCE_LENGTH",
      "optional": true}], "name": "open-vaccine-123456"}'}
  labels: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.2}
spec:
  entrypoint: open-vaccine-123456
  templates:
  - name: kale-marshal-volume
    resource:
      action: create
      manifest: |
        apiVersion: v1
        kind: PersistentVolumeClaim
        metadata:
          name: '{{workflow.name}}-kale-marshal-pvc'
        spec:
          accessModes:
          - ReadWriteMany
          resources:
            requests:
              storage: 20Gi
    outputs:
      parameters:
      - name: kale-marshal-volume-manifest
        valueFrom: {jsonPath: '{}'}
      - name: kale-marshal-volume-name
        valueFrom: {jsonPath: '{.metadata.name}'}
      - name: kale-marshal-volume-size
        valueFrom: {jsonPath: '{.status.capacity.storage}'}
    metadata:
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.2
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "false"
  - name: load-data
    container:
      args: []
      command:
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - "def load_data():\n    from kale.common import mlmdutils as _kale_mlmdutils\n\
        \    _kale_mlmdutils.init_metadata()\n\n    _kale_block1 = '''\n    import\
        \ json\n    import numpy as np\n    import pandas as pd\n    import tensorflow\
        \ as tf\n    import os \n\n    from tensorflow.keras.preprocessing.text import\
        \ Tokenizer\n    '''\n\n    _kale_block2 = '''\n    # train_df = pd.read_json(\"\
        data/train.json\", lines=True)\n    # test_df = pd.read_json(\"data/test.json\"\
        , lines=True)\n    '''\n\n    _kale_block3 = '''\n    test_df = {\"index\"\
        :0,\"id\":\"id_00073f8be\",\"sequence\":\"GGAAAAGUACGACUUGAGUACGGAAAACGUACCAACUCGAUUAAAAUGGUCAAAGAGGUCGAAAUACAGAUGACCUUCGGGUUAUCAAAAGAAACAACAACAACAAC\"\
        ,\"structure\":\"......((((((((((.(((((.....))))))))((((((((...)))))...)))))))...))).(((((((....))))))).....................\"\
        ,\"predicted_loop_type\":\"EEEEEESSSSSSSSSSBSSSSSHHHHHSSSSSSSSSSSSSSSSHHHSSSSSBBBSSSSSSSBBBSSSXSSSSSSSHHHHSSSSSSSEEEEEEEEEEEEEEEEEEEEE\"\
        ,\"seq_length\":107,\"seq_scored\":68}\n    '''\n\n    _kale_block4 = '''\n\
        \    train_df = {\"index\":0,\"id\":\"id_001f94081\",\"sequence\":\"GGAAAAGCUCUAAUAACAGGAGACUAGGACUACGUAUUUCUAGGUAACUGGAAUAACCCAUACCAGCAGUUAGAGUUCGCUCUAACAAAAGAAACAACAACAACAAC\"\
        ,\"structure\":\".....((((((.......)))).)).((.....((..((((((....))))))..)).....))....(((((((....))))))).....................\"\
        ,\"predicted_loop_type\":\"EEEEESSSSSSHHHHHHHSSSSBSSXSSIIIIISSIISSSSSSHHHHSSSSSSIISSIIIIISSXXXXSSSSSSSHHHHSSSSSSSEEEEEEEEEEEEEEEEEEEEE\"\
        ,\"signal_to_noise\":6.894,\"SN_filter\":1.0,\"seq_length\":107,\"seq_scored\"\
        :68,\"reactivity_error\":[0.1359,0.207,0.1633,0.1452,0.1314,0.105,0.0821,0.0964,0.0756,0.1087,0.1377,0.1544,0.1622,0.1388,0.1284,0.1009,0.0941,0.0564,0.0417,0.0596,0.0482,0.1041,0.0942,0.052,0.0583,0.0403,0.0491,0.1003,0.0525,0.081,0.1103,0.0707,0.0797,0.0997,0.0968,0.0939,0.0931,0.0604,0.0427,0.0331,0.0412,0.0286,0.0415,0.0394,0.0636,0.0816,0.0474,0.0295,0.0163,0.0211,0.0426,0.0592,0.0778,0.0579,0.0606,0.0462,0.0354,0.0324,0.0351,0.0539,0.0565,0.0489,0.0221,0.0254,0.0328,0.0394,0.0409,0.0547],\"\
        deg_error_Mg_pH10\":[0.2613,0.3842,0.1372,0.2531,0.1798,0.1371,0.1736,0.1791,0.1056,0.1896,0.1834,0.1659,0.2108,0.181,0.1353,0.128,0.1296,0.0949,0.0796,0.088,0.0536,0.0997,0.0757,0.0973,0.0874,0.0767,0.0476,0.0916,0.0673,0.0858,0.0976,0.0662,0.0747,0.1119,0.1036,0.1,0.0907,0.0702,0.0394,0.05,0.0507,0.0396,0.0541,0.0862,0.0832,0.0793,0.0606,0.0511,0.0212,0.0338,0.0573,0.0503,0.1026,0.0449,0.0452,0.0395,0.0417,0.033,0.0417,0.0483,0.0517,0.0404,0.0274,0.0271,0.0306,0.0384,0.0516,0.0523],\"\
        deg_error_pH10\":[0.2631,0.286,0.0964,0.1574,0.1,0.1019,0.114,0.1341,0.0517,0.1474,0.124,0.0966,0.1564,0.1417,0.1036,0.1142,0.1423,0.105,0.0806,0.0769,0.0701,0.1103,0.0847,0.095,0.0932,0.0952,0.062,0.1367,0.0846,0.0883,0.1514,0.0678,0.119,0.1442,0.134,0.125,0.134,0.0934,0.0622,0.0703,0.0866,0.0546,0.0712,0.0955,0.0951,0.0912,0.0768,0.0674,0.0324,0.0496,0.076,0.0705,0.1172,0.063,0.0752,0.0603,0.069,0.067,0.0803,0.1006,0.1042,0.0788,0.0688,0.0756,0.0675,0.0813,0.1021,0.1191],\"\
        deg_error_Mg_50C\":[0.1501,0.275,0.0947,0.1866,0.1369,0.1148,0.0995,0.1449,0.0705,0.1588,0.1496,0.121,0.1767,0.1382,0.111,0.112,0.1151,0.0836,0.067,0.0794,0.0464,0.0806,0.0678,0.0824,0.0671,0.0675,0.0612,0.0763,0.0759,0.0853,0.1042,0.0581,0.0924,0.1177,0.1025,0.1006,0.0986,0.078,0.0455,0.0658,0.0583,0.0417,0.0468,0.0787,0.0738,0.0653,0.0502,0.0512,0.0199,0.0285,0.0508,0.0564,0.1069,0.0487,0.0509,0.0433,0.0449,0.0421,0.0548,0.0623,0.0513,0.0528,0.0379,0.0439,0.0462,0.0544,0.0663,0.057],\"\
        deg_error_50C\":[0.2167,0.3475,0.188,0.2124,0.1703,0.1481,0.1352,0.1834,0.0638,0.1804,0.1915,0.1713,0.163,0.1777,0.1541,0.1327,0.1608,0.123,0.0927,0.1024,0.0872,0.1352,0.1034,0.1198,0.1173,0.1233,0.09,0.1543,0.1054,0.1166,0.1531,0.0904,0.1466,0.1726,0.151,0.1333,0.1484,0.11,0.0666,0.0904,0.0982,0.0608,0.0803,0.1014,0.1159,0.1042,0.0783,0.0757,0.0416,0.0582,0.0894,0.0881,0.1127,0.0622,0.0795,0.0604,0.0611,0.0592,0.0805,0.0817,0.0809,0.0719,0.0584,0.0649,0.0817,0.0717,0.0924,0.1093],\"\
        reactivity\":[0.3297,1.5693,1.1227,0.8686,0.7217,0.4384,0.256,0.3364,0.2168,0.3583,0.9541,1.4113,1.6911,1.2494,1.1895,0.6909,0.4736,0.1754,0.0582,0.2173,0.0785,0.8249,0.7638,0.1095,0.2568,0.0895,0.1576,0.7727,0.1573,0.5043,1.0444,0.4766,0.5588,0.9054,1.0125,1.0482,1.044,0.4522,0.211,0.0461,0.082,0.0643,0.1526,0.0894,0.5081,1.0745,0.3215,0.0716,0.0244,0.0123,0.1984,0.4961,1.0641,0.6394,0.6789,0.365,0.1741,0.1408,0.1646,0.5389,0.683,0.4273,0.0527,0.0693,0.1398,0.2937,0.2362,0.5731],\"\
        deg_Mg_pH10\":[0.7556,2.983,0.2526,1.3789,0.6376,0.3313,0.6763,0.7525,0.208,0.8908,0.9898,0.8679,1.7403,1.3795,0.7746,0.719,0.7229,0.4069,0.2632,0.3631,0.0702,0.4765,0.2766,0.4936,0.4379,0.3261,0.0898,0.4159,0.2264,0.4142,0.5213,0.2653,0.3163,0.9059,0.8762,0.8991,0.7262,0.4762,0.1187,0.1952,0.1777,0.1281,0.2664,0.8831,0.8752,0.8693,0.5119,0.3476,0.0438,0.1236,0.458,0.3214,2.1155,0.3708,0.3536,0.2669,0.3161,0.1793,0.3259,0.47,0.6141,0.3122,0.1418,0.1277,0.1608,0.3336,0.6491,0.6898],\"\
        deg_pH10\":[2.3375,3.506,0.3008,1.0108,0.2635,0.3403,0.5617,0.681,0.053,0.5348,0.5526,0.3278,1.0806,0.7699,0.3901,0.5045,0.6475,0.5176,0.2206,0.2255,0.0581,0.4302,0.3344,0.2718,0.466,0.4763,0.1275,0.6886,0.2323,0.1186,0.8321,0.1317,0.5878,0.7162,0.7943,0.7224,0.8105,0.4782,0.1797,0.1344,0.2217,0.1152,0.1707,0.4324,0.4166,0.4558,0.3606,0.2239,0.0481,0.0691,0.2423,0.1003,0.9322,0.253,0.2923,0.1455,0.2523,0.2504,0.4065,0.7361,0.9412,0.3137,0.3489,0.414,0.2238,0.5142,0.7681,1.172],\"\
        deg_Mg_50C\":[0.3581,2.9683,0.2589,1.4552,0.7244,0.4971,0.3819,0.9115,0.1668,1.0613,1.1317,0.7468,1.9049,1.103,0.7317,0.7649,0.701,0.4327,0.236,0.4039,0.0373,0.3362,0.2914,0.3956,0.3074,0.3079,0.2379,0.2027,0.3721,0.4504,0.6303,0.2092,0.6219,1.0619,0.8667,0.9206,0.8516,0.6308,0.1756,0.4022,0.2236,0.1452,0.1469,0.6622,0.5692,0.4583,0.2705,0.2798,0.0298,0.0367,0.2299,0.2873,1.7464,0.3233,0.2996,0.2029,0.2311,0.2032,0.4079,0.5544,0.3829,0.3445,0.1898,0.2649,0.2714,0.4812,0.7026,0.4254],\"\
        deg_50C\":[0.6382,3.4773,0.9988,1.3228,0.7877,0.589,0.5231,1.0125,0.0585,0.7349,1.2215,1.0321,0.8274,1.0442,0.8472,0.5547,0.7291,0.5541,0.2404,0.3598,0.1496,0.6154,0.4053,0.4641,0.5976,0.6747,0.2979,0.8376,0.3915,0.4226,0.7223,0.2991,0.9497,1.2491,1.0324,0.7868,1.0355,0.6604,0.1921,0.3593,0.3799,0.151,0.2636,0.4919,0.7486,0.6304,0.3466,0.3033,0.0855,0.1387,0.4254,0.3571,0.794,0.2258,0.3457,0.1514,0.1602,0.1572,0.3912,0.3724,0.4432,0.2169,0.1959,0.2391,0.4234,0.3287,0.5301,0.8472]}\n\
        \    '''\n\n    _kale_block5 = '''\n\n    '''\n\n    _kale_block6 = '''\n\
        \    columns = []\n    data = []\n    for i in test_df:\n        data.append(test_df[i])\n\
        \        columns.append(i)\n    print(columns)\n    print(data)\n    test_df\
        \ = pd.DataFrame([data], columns=columns)\n    '''\n\n    _kale_block7 = '''\n\
        \    columns = []\n    data = []\n    for i in train_df:\n        print(i)\n\
        \        data.append(train_df[i])\n        columns.append(i)\n    # print(columns)\n\
        \    # print(data)\n    train_df = pd.DataFrame([data], columns=columns)\n\
        \    '''\n\n    _kale_block8 = '''\n    print(os.path.abspath('.'))\n    '''\n\
        \n    _kale_block9 = '''\n    # sample_submission_df = pd.read_csv(\"/home/jovyan/kale/examples/openvaccine-kaggle-competition/data/sample_submission.csv\"\
        )\n    '''\n\n    _kale_block10 = '''\n    data = [\"id_00073f8be_0\\t0.0\\\
        t0.0\\t0.0\\t0.0\\t0.0\".split('\\\\t')]\n    columns = \"id_seqpos\\treactivity\\\
        tdeg_Mg_pH10\\tdeg_pH10\\tdeg_Mg_50C\\tdeg_50C\".split('\\\\t')\n    '''\n\
        \n    _kale_block11 = '''\n    sample_submission_df = pd.DataFrame(data, columns=columns)\n\
        \    '''\n\n    _kale_block12 = '''\n\n    '''\n\n    _kale_data_saving_block\
        \ = '''\n    # -----------------------DATA SAVING START---------------------------------\n\
        \    from kale import marshal as _kale_marshal\n    _kale_marshal.set_data_dir(\"\
        /marshal\")\n    _kale_marshal.save(test_df, \"test_df\")\n    _kale_marshal.save(train_df,\
        \ \"train_df\")\n    # -----------------------DATA SAVING END-----------------------------------\n\
        \    '''\n\n    # run the code blocks inside a jupyter kernel\n    from kale.common.jputils\
        \ import run_code as _kale_run_code\n    from kale.common.kfputils import\
        \ \\\n        update_uimetadata as _kale_update_uimetadata\n    _kale_blocks\
        \ = (\n        _kale_block1,\n        _kale_block2,\n        _kale_block3,\n\
        \        _kale_block4,\n        _kale_block5,\n        _kale_block6,\n   \
        \     _kale_block7,\n        _kale_block8,\n        _kale_block9,\n      \
        \  _kale_block10,\n        _kale_block11,\n        _kale_block12,\n      \
        \  _kale_data_saving_block)\n    _kale_html_artifact = _kale_run_code(_kale_blocks)\n\
        \    with open(\"/load_data.html\", \"w\") as f:\n        f.write(_kale_html_artifact)\n\
        \    _kale_update_uimetadata('load_data')\n\n    _kale_mlmdutils.call(\"mark_execution_complete\"\
        )\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Load data',\
        \ description='')\n_parsed_args = vars(_parser.parse_args())\n\n_outputs =\
        \ load_data(**_parsed_args)\n"
      image: ' ali-art.hfinside.com/dev-v/app/jupyter-kale:20211116'
      securityContext: {runAsUser: 0}
      volumeMounts:
      - {mountPath: /marshal, name: kale-marshal-volume}
      workingDir: /home/jovyan/openvaccine-kaggle-competition
    inputs:
      parameters:
      - {name: kale-marshal-volume-name}
    outputs:
      artifacts:
      - {name: mlpipeline-ui-metadata, path: /tmp/mlpipeline-ui-metadata.json}
      - {name: load_data, path: /load_data.html}
    metadata:
      annotations: {kubeflow-kale.org/dependent-templates: '["kale-marshal-volume"]',
        kubeflow-kale.org/volume-name-parameters: '["kale-marshal-volume-name"]',
        pipelines.kubeflow.org/component_spec: '{"implementation": {"container": {"args":
          [], "command": ["sh", "-ec", "program_path=$(mktemp)\nprintf \"%s\" \"$0\"
          > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n", "def load_data():\n    from
          kale.common import mlmdutils as _kale_mlmdutils\n    _kale_mlmdutils.init_metadata()\n\n    _kale_block1
          = ''''''\n    import json\n    import numpy as np\n    import pandas as
          pd\n    import tensorflow as tf\n    import os \n\n    from tensorflow.keras.preprocessing.text
          import Tokenizer\n    ''''''\n\n    _kale_block2 = ''''''\n    # train_df
          = pd.read_json(\"data/train.json\", lines=True)\n    # test_df = pd.read_json(\"data/test.json\",
          lines=True)\n    ''''''\n\n    _kale_block3 = ''''''\n    test_df = {\"index\":0,\"id\":\"id_00073f8be\",\"sequence\":\"GGAAAAGUACGACUUGAGUACGGAAAACGUACCAACUCGAUUAAAAUGGUCAAAGAGGUCGAAAUACAGAUGACCUUCGGGUUAUCAAAAGAAACAACAACAACAAC\",\"structure\":\"......((((((((((.(((((.....))))))))((((((((...)))))...)))))))...))).(((((((....))))))).....................\",\"predicted_loop_type\":\"EEEEEESSSSSSSSSSBSSSSSHHHHHSSSSSSSSSSSSSSSSHHHSSSSSBBBSSSSSSSBBBSSSXSSSSSSSHHHHSSSSSSSEEEEEEEEEEEEEEEEEEEEE\",\"seq_length\":107,\"seq_scored\":68}\n    ''''''\n\n    _kale_block4
          = ''''''\n    train_df = {\"index\":0,\"id\":\"id_001f94081\",\"sequence\":\"GGAAAAGCUCUAAUAACAGGAGACUAGGACUACGUAUUUCUAGGUAACUGGAAUAACCCAUACCAGCAGUUAGAGUUCGCUCUAACAAAAGAAACAACAACAACAAC\",\"structure\":\".....((((((.......)))).)).((.....((..((((((....))))))..)).....))....(((((((....))))))).....................\",\"predicted_loop_type\":\"EEEEESSSSSSHHHHHHHSSSSBSSXSSIIIIISSIISSSSSSHHHHSSSSSSIISSIIIIISSXXXXSSSSSSSHHHHSSSSSSSEEEEEEEEEEEEEEEEEEEEE\",\"signal_to_noise\":6.894,\"SN_filter\":1.0,\"seq_length\":107,\"seq_scored\":68,\"reactivity_error\":[0.1359,0.207,0.1633,0.1452,0.1314,0.105,0.0821,0.0964,0.0756,0.1087,0.1377,0.1544,0.1622,0.1388,0.1284,0.1009,0.0941,0.0564,0.0417,0.0596,0.0482,0.1041,0.0942,0.052,0.0583,0.0403,0.0491,0.1003,0.0525,0.081,0.1103,0.0707,0.0797,0.0997,0.0968,0.0939,0.0931,0.0604,0.0427,0.0331,0.0412,0.0286,0.0415,0.0394,0.0636,0.0816,0.0474,0.0295,0.0163,0.0211,0.0426,0.0592,0.0778,0.0579,0.0606,0.0462,0.0354,0.0324,0.0351,0.0539,0.0565,0.0489,0.0221,0.0254,0.0328,0.0394,0.0409,0.0547],\"deg_error_Mg_pH10\":[0.2613,0.3842,0.1372,0.2531,0.1798,0.1371,0.1736,0.1791,0.1056,0.1896,0.1834,0.1659,0.2108,0.181,0.1353,0.128,0.1296,0.0949,0.0796,0.088,0.0536,0.0997,0.0757,0.0973,0.0874,0.0767,0.0476,0.0916,0.0673,0.0858,0.0976,0.0662,0.0747,0.1119,0.1036,0.1,0.0907,0.0702,0.0394,0.05,0.0507,0.0396,0.0541,0.0862,0.0832,0.0793,0.0606,0.0511,0.0212,0.0338,0.0573,0.0503,0.1026,0.0449,0.0452,0.0395,0.0417,0.033,0.0417,0.0483,0.0517,0.0404,0.0274,0.0271,0.0306,0.0384,0.0516,0.0523],\"deg_error_pH10\":[0.2631,0.286,0.0964,0.1574,0.1,0.1019,0.114,0.1341,0.0517,0.1474,0.124,0.0966,0.1564,0.1417,0.1036,0.1142,0.1423,0.105,0.0806,0.0769,0.0701,0.1103,0.0847,0.095,0.0932,0.0952,0.062,0.1367,0.0846,0.0883,0.1514,0.0678,0.119,0.1442,0.134,0.125,0.134,0.0934,0.0622,0.0703,0.0866,0.0546,0.0712,0.0955,0.0951,0.0912,0.0768,0.0674,0.0324,0.0496,0.076,0.0705,0.1172,0.063,0.0752,0.0603,0.069,0.067,0.0803,0.1006,0.1042,0.0788,0.0688,0.0756,0.0675,0.0813,0.1021,0.1191],\"deg_error_Mg_50C\":[0.1501,0.275,0.0947,0.1866,0.1369,0.1148,0.0995,0.1449,0.0705,0.1588,0.1496,0.121,0.1767,0.1382,0.111,0.112,0.1151,0.0836,0.067,0.0794,0.0464,0.0806,0.0678,0.0824,0.0671,0.0675,0.0612,0.0763,0.0759,0.0853,0.1042,0.0581,0.0924,0.1177,0.1025,0.1006,0.0986,0.078,0.0455,0.0658,0.0583,0.0417,0.0468,0.0787,0.0738,0.0653,0.0502,0.0512,0.0199,0.0285,0.0508,0.0564,0.1069,0.0487,0.0509,0.0433,0.0449,0.0421,0.0548,0.0623,0.0513,0.0528,0.0379,0.0439,0.0462,0.0544,0.0663,0.057],\"deg_error_50C\":[0.2167,0.3475,0.188,0.2124,0.1703,0.1481,0.1352,0.1834,0.0638,0.1804,0.1915,0.1713,0.163,0.1777,0.1541,0.1327,0.1608,0.123,0.0927,0.1024,0.0872,0.1352,0.1034,0.1198,0.1173,0.1233,0.09,0.1543,0.1054,0.1166,0.1531,0.0904,0.1466,0.1726,0.151,0.1333,0.1484,0.11,0.0666,0.0904,0.0982,0.0608,0.0803,0.1014,0.1159,0.1042,0.0783,0.0757,0.0416,0.0582,0.0894,0.0881,0.1127,0.0622,0.0795,0.0604,0.0611,0.0592,0.0805,0.0817,0.0809,0.0719,0.0584,0.0649,0.0817,0.0717,0.0924,0.1093],\"reactivity\":[0.3297,1.5693,1.1227,0.8686,0.7217,0.4384,0.256,0.3364,0.2168,0.3583,0.9541,1.4113,1.6911,1.2494,1.1895,0.6909,0.4736,0.1754,0.0582,0.2173,0.0785,0.8249,0.7638,0.1095,0.2568,0.0895,0.1576,0.7727,0.1573,0.5043,1.0444,0.4766,0.5588,0.9054,1.0125,1.0482,1.044,0.4522,0.211,0.0461,0.082,0.0643,0.1526,0.0894,0.5081,1.0745,0.3215,0.0716,0.0244,0.0123,0.1984,0.4961,1.0641,0.6394,0.6789,0.365,0.1741,0.1408,0.1646,0.5389,0.683,0.4273,0.0527,0.0693,0.1398,0.2937,0.2362,0.5731],\"deg_Mg_pH10\":[0.7556,2.983,0.2526,1.3789,0.6376,0.3313,0.6763,0.7525,0.208,0.8908,0.9898,0.8679,1.7403,1.3795,0.7746,0.719,0.7229,0.4069,0.2632,0.3631,0.0702,0.4765,0.2766,0.4936,0.4379,0.3261,0.0898,0.4159,0.2264,0.4142,0.5213,0.2653,0.3163,0.9059,0.8762,0.8991,0.7262,0.4762,0.1187,0.1952,0.1777,0.1281,0.2664,0.8831,0.8752,0.8693,0.5119,0.3476,0.0438,0.1236,0.458,0.3214,2.1155,0.3708,0.3536,0.2669,0.3161,0.1793,0.3259,0.47,0.6141,0.3122,0.1418,0.1277,0.1608,0.3336,0.6491,0.6898],\"deg_pH10\":[2.3375,3.506,0.3008,1.0108,0.2635,0.3403,0.5617,0.681,0.053,0.5348,0.5526,0.3278,1.0806,0.7699,0.3901,0.5045,0.6475,0.5176,0.2206,0.2255,0.0581,0.4302,0.3344,0.2718,0.466,0.4763,0.1275,0.6886,0.2323,0.1186,0.8321,0.1317,0.5878,0.7162,0.7943,0.7224,0.8105,0.4782,0.1797,0.1344,0.2217,0.1152,0.1707,0.4324,0.4166,0.4558,0.3606,0.2239,0.0481,0.0691,0.2423,0.1003,0.9322,0.253,0.2923,0.1455,0.2523,0.2504,0.4065,0.7361,0.9412,0.3137,0.3489,0.414,0.2238,0.5142,0.7681,1.172],\"deg_Mg_50C\":[0.3581,2.9683,0.2589,1.4552,0.7244,0.4971,0.3819,0.9115,0.1668,1.0613,1.1317,0.7468,1.9049,1.103,0.7317,0.7649,0.701,0.4327,0.236,0.4039,0.0373,0.3362,0.2914,0.3956,0.3074,0.3079,0.2379,0.2027,0.3721,0.4504,0.6303,0.2092,0.6219,1.0619,0.8667,0.9206,0.8516,0.6308,0.1756,0.4022,0.2236,0.1452,0.1469,0.6622,0.5692,0.4583,0.2705,0.2798,0.0298,0.0367,0.2299,0.2873,1.7464,0.3233,0.2996,0.2029,0.2311,0.2032,0.4079,0.5544,0.3829,0.3445,0.1898,0.2649,0.2714,0.4812,0.7026,0.4254],\"deg_50C\":[0.6382,3.4773,0.9988,1.3228,0.7877,0.589,0.5231,1.0125,0.0585,0.7349,1.2215,1.0321,0.8274,1.0442,0.8472,0.5547,0.7291,0.5541,0.2404,0.3598,0.1496,0.6154,0.4053,0.4641,0.5976,0.6747,0.2979,0.8376,0.3915,0.4226,0.7223,0.2991,0.9497,1.2491,1.0324,0.7868,1.0355,0.6604,0.1921,0.3593,0.3799,0.151,0.2636,0.4919,0.7486,0.6304,0.3466,0.3033,0.0855,0.1387,0.4254,0.3571,0.794,0.2258,0.3457,0.1514,0.1602,0.1572,0.3912,0.3724,0.4432,0.2169,0.1959,0.2391,0.4234,0.3287,0.5301,0.8472]}\n    ''''''\n\n    _kale_block5
          = ''''''\n\n    ''''''\n\n    _kale_block6 = ''''''\n    columns = []\n    data
          = []\n    for i in test_df:\n        data.append(test_df[i])\n        columns.append(i)\n    print(columns)\n    print(data)\n    test_df
          = pd.DataFrame([data], columns=columns)\n    ''''''\n\n    _kale_block7
          = ''''''\n    columns = []\n    data = []\n    for i in train_df:\n        print(i)\n        data.append(train_df[i])\n        columns.append(i)\n    #
          print(columns)\n    # print(data)\n    train_df = pd.DataFrame([data], columns=columns)\n    ''''''\n\n    _kale_block8
          = ''''''\n    print(os.path.abspath(''.''))\n    ''''''\n\n    _kale_block9
          = ''''''\n    # sample_submission_df = pd.read_csv(\"/home/jovyan/kale/examples/openvaccine-kaggle-competition/data/sample_submission.csv\")\n    ''''''\n\n    _kale_block10
          = ''''''\n    data = [\"id_00073f8be_0\\t0.0\\t0.0\\t0.0\\t0.0\\t0.0\".split(''\\\\t'')]\n    columns
          = \"id_seqpos\\treactivity\\tdeg_Mg_pH10\\tdeg_pH10\\tdeg_Mg_50C\\tdeg_50C\".split(''\\\\t'')\n    ''''''\n\n    _kale_block11
          = ''''''\n    sample_submission_df = pd.DataFrame(data, columns=columns)\n    ''''''\n\n    _kale_block12
          = ''''''\n\n    ''''''\n\n    _kale_data_saving_block = ''''''\n    # -----------------------DATA
          SAVING START---------------------------------\n    from kale import marshal
          as _kale_marshal\n    _kale_marshal.set_data_dir(\"/marshal\")\n    _kale_marshal.save(test_df,
          \"test_df\")\n    _kale_marshal.save(train_df, \"train_df\")\n    # -----------------------DATA
          SAVING END-----------------------------------\n    ''''''\n\n    # run the
          code blocks inside a jupyter kernel\n    from kale.common.jputils import
          run_code as _kale_run_code\n    from kale.common.kfputils import \\\n        update_uimetadata
          as _kale_update_uimetadata\n    _kale_blocks = (\n        _kale_block1,\n        _kale_block2,\n        _kale_block3,\n        _kale_block4,\n        _kale_block5,\n        _kale_block6,\n        _kale_block7,\n        _kale_block8,\n        _kale_block9,\n        _kale_block10,\n        _kale_block11,\n        _kale_block12,\n        _kale_data_saving_block)\n    _kale_html_artifact
          = _kale_run_code(_kale_blocks)\n    with open(\"/load_data.html\", \"w\")
          as f:\n        f.write(_kale_html_artifact)\n    _kale_update_uimetadata(''load_data'')\n\n    _kale_mlmdutils.call(\"mark_execution_complete\")\n\nimport
          argparse\n_parser = argparse.ArgumentParser(prog=''Load data'', description='''')\n_parsed_args
          = vars(_parser.parse_args())\n\n_outputs = load_data(**_parsed_args)\n"],
          "image": " ali-art.hfinside.com/dev-v/app/jupyter-kale:20211116"}}, "name":
          "Load data"}', pipelines.kubeflow.org/component_ref: '{}'}
      labels:
        access-ml-pipeline: "true"
        pipelines.kubeflow.org/metadata_written: "true"
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.2
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "false"
    volumes:
    - name: kale-marshal-volume
      persistentVolumeClaim: {claimName: '{{inputs.parameters.kale-marshal-volume-name}}'}
  - name: model-evaluation
    container:
      args: [--DROPOUT, '{{inputs.parameters.DROPOUT}}', --EMBED-DIM, '{{inputs.parameters.EMBED_DIM}}',
        --HIDDEN-DIM, '{{inputs.parameters.HIDDEN_DIM}}', --SP-DROPOUT, '{{inputs.parameters.SP_DROPOUT}}',
        --TRAIN-SEQUENCE-LENGTH, '{{inputs.parameters.TRAIN_SEQUENCE_LENGTH}}']
      command:
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - "def model_evaluation(DROPOUT, EMBED_DIM, HIDDEN_DIM, SP_DROPOUT, TRAIN_SEQUENCE_LENGTH):\n\
        \    _kale_pipeline_parameters_block = '''\n    DROPOUT = {}\n    EMBED_DIM\
        \ = {}\n    HIDDEN_DIM = {}\n    SP_DROPOUT = {}\n    TRAIN_SEQUENCE_LENGTH\
        \ = {}\n    '''.format(DROPOUT, EMBED_DIM, HIDDEN_DIM, SP_DROPOUT, TRAIN_SEQUENCE_LENGTH)\n\
        \n    from kale.common import mlmdutils as _kale_mlmdutils\n    _kale_mlmdutils.init_metadata()\n\
        \n    _kale_data_loading_block = '''\n    # -----------------------DATA LOADING\
        \ START--------------------------------\n    from kale import marshal as _kale_marshal\n\
        \    _kale_marshal.set_data_dir(\"/marshal\")\n    build_model = _kale_marshal.load(\"\
        build_model\")\n    gru_layer = _kale_marshal.load(\"gru_layer\")\n    lstm_layer\
        \ = _kale_marshal.load(\"lstm_layer\")\n    model = _kale_marshal.load(\"\
        model\")\n    process_features = _kale_marshal.load(\"process_features\")\n\
        \    tokenizer = _kale_marshal.load(\"tokenizer\")\n    unprocessed_x_private_test\
        \ = _kale_marshal.load(\"unprocessed_x_private_test\")\n    unprocessed_x_public_test\
        \ = _kale_marshal.load(\"unprocessed_x_public_test\")\n    vocab_size = _kale_marshal.load(\"\
        vocab_size\")\n    # -----------------------DATA LOADING END----------------------------------\n\
        \    '''\n\n    _kale_block1 = '''\n    import json\n    import numpy as np\n\
        \    import pandas as pd\n    import tensorflow as tf\n    import os \n\n\
        \    from tensorflow.keras.preprocessing.text import Tokenizer\n    '''\n\n\
        \    _kale_block2 = '''\n    model_public = build_model(vocab_size, seq_length=107,\
        \ pred_len=107)\n    model_private = build_model(vocab_size, seq_length=130,\
        \ pred_len=130)\n\n    model_public.set_weights(model.get_weights())\n   \
        \ model_private.set_weights(model.get_weights())\n    '''\n\n    _kale_block3\
        \ = '''\n    public_preds = model_public.predict(np.array([process_features(x)\
        \ for x in unprocessed_x_public_test]))\n    private_preds = model_private.predict(np.array([process_features(x)\
        \ for x in unprocessed_x_private_test]))\n    '''\n\n    _kale_block4 = '''\n\
        \    from kale.common.serveutils import serve\n    '''\n\n    _kale_block5\
        \ = '''\n\n    '''\n\n    _kale_block6 = '''\n\n    '''\n\n    # run the code\
        \ blocks inside a jupyter kernel\n    from kale.common.jputils import run_code\
        \ as _kale_run_code\n    from kale.common.kfputils import \\\n        update_uimetadata\
        \ as _kale_update_uimetadata\n    _kale_blocks = (_kale_pipeline_parameters_block,\
        \ _kale_data_loading_block,\n                    _kale_block1,\n         \
        \           _kale_block2,\n                    _kale_block3,\n           \
        \         _kale_block4,\n                    _kale_block5,\n             \
        \       _kale_block6,\n                    )\n    _kale_html_artifact = _kale_run_code(_kale_blocks)\n\
        \    with open(\"/model_evaluation.html\", \"w\") as f:\n        f.write(_kale_html_artifact)\n\
        \    _kale_update_uimetadata('model_evaluation')\n\n    _kale_mlmdutils.call(\"\
        mark_execution_complete\")\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Model\
        \ evaluation', description='')\n_parser.add_argument(\"--DROPOUT\", dest=\"\
        DROPOUT\", type=float, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"\
        --EMBED-DIM\", dest=\"EMBED_DIM\", type=int, required=True, default=argparse.SUPPRESS)\n\
        _parser.add_argument(\"--HIDDEN-DIM\", dest=\"HIDDEN_DIM\", type=int, required=True,\
        \ default=argparse.SUPPRESS)\n_parser.add_argument(\"--SP-DROPOUT\", dest=\"\
        SP_DROPOUT\", type=float, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"\
        --TRAIN-SEQUENCE-LENGTH\", dest=\"TRAIN_SEQUENCE_LENGTH\", type=int, required=True,\
        \ default=argparse.SUPPRESS)\n_parsed_args = vars(_parser.parse_args())\n\n\
        _outputs = model_evaluation(**_parsed_args)\n"
      image: ' ali-art.hfinside.com/dev-v/app/jupyter-kale:20211116'
      securityContext: {runAsUser: 0}
      volumeMounts:
      - {mountPath: /marshal, name: kale-marshal-volume}
      workingDir: /home/jovyan/openvaccine-kaggle-competition
    inputs:
      parameters:
      - {name: DROPOUT}
      - {name: EMBED_DIM}
      - {name: HIDDEN_DIM}
      - {name: SP_DROPOUT}
      - {name: TRAIN_SEQUENCE_LENGTH}
      - {name: kale-marshal-volume-name}
    outputs:
      artifacts:
      - {name: mlpipeline-ui-metadata, path: /tmp/mlpipeline-ui-metadata.json}
      - {name: model_evaluation, path: /model_evaluation.html}
    metadata:
      annotations: {kubeflow-kale.org/dependent-templates: '["model-training", "kale-marshal-volume"]',
        kubeflow-kale.org/volume-name-parameters: '["kale-marshal-volume-name"]',
        pipelines.kubeflow.org/component_spec: '{"implementation": {"container": {"args":
          ["--DROPOUT", {"inputValue": "DROPOUT"}, "--EMBED-DIM", {"inputValue": "EMBED_DIM"},
          "--HIDDEN-DIM", {"inputValue": "HIDDEN_DIM"}, "--SP-DROPOUT", {"inputValue":
          "SP_DROPOUT"}, "--TRAIN-SEQUENCE-LENGTH", {"inputValue": "TRAIN_SEQUENCE_LENGTH"}],
          "command": ["sh", "-ec", "program_path=$(mktemp)\nprintf \"%s\" \"$0\" >
          \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n", "def model_evaluation(DROPOUT,
          EMBED_DIM, HIDDEN_DIM, SP_DROPOUT, TRAIN_SEQUENCE_LENGTH):\n    _kale_pipeline_parameters_block
          = ''''''\n    DROPOUT = {}\n    EMBED_DIM = {}\n    HIDDEN_DIM = {}\n    SP_DROPOUT
          = {}\n    TRAIN_SEQUENCE_LENGTH = {}\n    ''''''.format(DROPOUT, EMBED_DIM,
          HIDDEN_DIM, SP_DROPOUT, TRAIN_SEQUENCE_LENGTH)\n\n    from kale.common import
          mlmdutils as _kale_mlmdutils\n    _kale_mlmdutils.init_metadata()\n\n    _kale_data_loading_block
          = ''''''\n    # -----------------------DATA LOADING START--------------------------------\n    from
          kale import marshal as _kale_marshal\n    _kale_marshal.set_data_dir(\"/marshal\")\n    build_model
          = _kale_marshal.load(\"build_model\")\n    gru_layer = _kale_marshal.load(\"gru_layer\")\n    lstm_layer
          = _kale_marshal.load(\"lstm_layer\")\n    model = _kale_marshal.load(\"model\")\n    process_features
          = _kale_marshal.load(\"process_features\")\n    tokenizer = _kale_marshal.load(\"tokenizer\")\n    unprocessed_x_private_test
          = _kale_marshal.load(\"unprocessed_x_private_test\")\n    unprocessed_x_public_test
          = _kale_marshal.load(\"unprocessed_x_public_test\")\n    vocab_size = _kale_marshal.load(\"vocab_size\")\n    #
          -----------------------DATA LOADING END----------------------------------\n    ''''''\n\n    _kale_block1
          = ''''''\n    import json\n    import numpy as np\n    import pandas as
          pd\n    import tensorflow as tf\n    import os \n\n    from tensorflow.keras.preprocessing.text
          import Tokenizer\n    ''''''\n\n    _kale_block2 = ''''''\n    model_public
          = build_model(vocab_size, seq_length=107, pred_len=107)\n    model_private
          = build_model(vocab_size, seq_length=130, pred_len=130)\n\n    model_public.set_weights(model.get_weights())\n    model_private.set_weights(model.get_weights())\n    ''''''\n\n    _kale_block3
          = ''''''\n    public_preds = model_public.predict(np.array([process_features(x)
          for x in unprocessed_x_public_test]))\n    private_preds = model_private.predict(np.array([process_features(x)
          for x in unprocessed_x_private_test]))\n    ''''''\n\n    _kale_block4 =
          ''''''\n    from kale.common.serveutils import serve\n    ''''''\n\n    _kale_block5
          = ''''''\n\n    ''''''\n\n    _kale_block6 = ''''''\n\n    ''''''\n\n    #
          run the code blocks inside a jupyter kernel\n    from kale.common.jputils
          import run_code as _kale_run_code\n    from kale.common.kfputils import
          \\\n        update_uimetadata as _kale_update_uimetadata\n    _kale_blocks
          = (_kale_pipeline_parameters_block, _kale_data_loading_block,\n                    _kale_block1,\n                    _kale_block2,\n                    _kale_block3,\n                    _kale_block4,\n                    _kale_block5,\n                    _kale_block6,\n                    )\n    _kale_html_artifact
          = _kale_run_code(_kale_blocks)\n    with open(\"/model_evaluation.html\",
          \"w\") as f:\n        f.write(_kale_html_artifact)\n    _kale_update_uimetadata(''model_evaluation'')\n\n    _kale_mlmdutils.call(\"mark_execution_complete\")\n\nimport
          argparse\n_parser = argparse.ArgumentParser(prog=''Model evaluation'', description='''')\n_parser.add_argument(\"--DROPOUT\",
          dest=\"DROPOUT\", type=float, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--EMBED-DIM\",
          dest=\"EMBED_DIM\", type=int, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--HIDDEN-DIM\",
          dest=\"HIDDEN_DIM\", type=int, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--SP-DROPOUT\",
          dest=\"SP_DROPOUT\", type=float, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--TRAIN-SEQUENCE-LENGTH\",
          dest=\"TRAIN_SEQUENCE_LENGTH\", type=int, required=True, default=argparse.SUPPRESS)\n_parsed_args
          = vars(_parser.parse_args())\n\n_outputs = model_evaluation(**_parsed_args)\n"],
          "image": " ali-art.hfinside.com/dev-v/app/jupyter-kale:20211116"}}, "inputs":
          [{"name": "DROPOUT", "type": "Float"}, {"name": "EMBED_DIM", "type": "Integer"},
          {"name": "HIDDEN_DIM", "type": "Integer"}, {"name": "SP_DROPOUT", "type":
          "Float"}, {"name": "TRAIN_SEQUENCE_LENGTH", "type": "Integer"}], "name":
          "Model evaluation"}', pipelines.kubeflow.org/component_ref: '{}', pipelines.kubeflow.org/arguments.parameters: '{"DROPOUT":
          "{{inputs.parameters.DROPOUT}}", "EMBED_DIM": "{{inputs.parameters.EMBED_DIM}}",
          "HIDDEN_DIM": "{{inputs.parameters.HIDDEN_DIM}}", "SP_DROPOUT": "{{inputs.parameters.SP_DROPOUT}}",
          "TRAIN_SEQUENCE_LENGTH": "{{inputs.parameters.TRAIN_SEQUENCE_LENGTH}}"}'}
      labels:
        access-ml-pipeline: "true"
        pipelines.kubeflow.org/metadata_written: "true"
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.2
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "false"
    volumes:
    - name: kale-marshal-volume
      persistentVolumeClaim: {claimName: '{{inputs.parameters.kale-marshal-volume-name}}'}
  - name: model-training
    container:
      args: [--BATCH-SIZE, '{{inputs.parameters.BATCH_SIZE}}', --DROPOUT, '{{inputs.parameters.DROPOUT}}',
        --EMBED-DIM, '{{inputs.parameters.EMBED_DIM}}', --EPOCHS, '{{inputs.parameters.EPOCHS}}',
        --HIDDEN-DIM, '{{inputs.parameters.HIDDEN_DIM}}', --LR, '{{inputs.parameters.LR}}',
        --SP-DROPOUT, '{{inputs.parameters.SP_DROPOUT}}', --TRAIN-SEQUENCE-LENGTH,
        '{{inputs.parameters.TRAIN_SEQUENCE_LENGTH}}']
      command:
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - "def model_training(BATCH_SIZE, DROPOUT, EMBED_DIM, EPOCHS, HIDDEN_DIM, LR,\
        \ SP_DROPOUT, TRAIN_SEQUENCE_LENGTH):\n    _kale_pipeline_parameters_block\
        \ = '''\n    BATCH_SIZE = {}\n    DROPOUT = {}\n    EMBED_DIM = {}\n    EPOCHS\
        \ = {}\n    HIDDEN_DIM = {}\n    LR = {}\n    SP_DROPOUT = {}\n    TRAIN_SEQUENCE_LENGTH\
        \ = {}\n    '''.format(BATCH_SIZE, DROPOUT, EMBED_DIM, EPOCHS, HIDDEN_DIM,\
        \ LR, SP_DROPOUT, TRAIN_SEQUENCE_LENGTH)\n\n    from kale.common import mlmdutils\
        \ as _kale_mlmdutils\n    _kale_mlmdutils.init_metadata()\n\n    _kale_data_loading_block\
        \ = '''\n    # -----------------------DATA LOADING START--------------------------------\n\
        \    from kale import marshal as _kale_marshal\n    _kale_marshal.set_data_dir(\"\
        /marshal\")\n    vocab_size = _kale_marshal.load(\"vocab_size\")\n    x_train\
        \ = _kale_marshal.load(\"x_train\")\n    y_train = _kale_marshal.load(\"y_train\"\
        )\n    # -----------------------DATA LOADING END----------------------------------\n\
        \    '''\n\n    _kale_block1 = '''\n    import json\n    import numpy as np\n\
        \    import pandas as pd\n    import tensorflow as tf\n    import os \n\n\
        \    from tensorflow.keras.preprocessing.text import Tokenizer\n    '''\n\n\
        \    _kale_block2 = '''\n    def gru_layer(hidden_dim, dropout):\n       \
        \ return tf.keras.layers.Bidirectional(\n             tf.keras.layers.GRU(hidden_dim,\
        \ dropout=dropout, return_sequences=True, kernel_initializer = 'orthogonal')\n\
        \        )\n    '''\n\n    _kale_block3 = '''\n    def lstm_layer(hidden_dim,\
        \ dropout):\n        return tf.keras.layers.Bidirectional(\n            tf.keras.layers.LSTM(hidden_dim,\
        \ dropout=dropout, return_sequences=True, kernel_initializer = 'orthogonal')\n\
        \        )\n    '''\n\n    _kale_block4 = '''\n    def build_model(vocab_size,\
        \ seq_length=int(TRAIN_SEQUENCE_LENGTH), pred_len=68,\n                  \
        \  embed_dim=int(EMBED_DIM),\n                    hidden_dim=int(HIDDEN_DIM),\
        \ dropout=float(DROPOUT), sp_dropout=float(SP_DROPOUT)):\n        inputs =\
        \ tf.keras.layers.Input(shape=(seq_length, 3))\n\n        embed = tf.keras.layers.Embedding(input_dim=vocab_size,\
        \ output_dim=embed_dim)(inputs)\n\n        reshaped = tf.reshape(\n      \
        \      embed, shape=(-1, embed.shape[1],  embed.shape[2] * embed.shape[3])\n\
        \        )\n\n        hidden = tf.keras.layers.SpatialDropout1D(sp_dropout)(reshaped)\n\
        \n        hidden = gru_layer(hidden_dim, dropout)(hidden)\n        hidden\
        \ = lstm_layer(hidden_dim, dropout)(hidden)\n\n        truncated = hidden[:,\
        \ :pred_len]\n\n        out = tf.keras.layers.Dense(5, activation=\"linear\"\
        )(truncated)\n\n        model = tf.keras.Model(inputs=inputs, outputs=out)\n\
        \n        return model\n    '''\n\n    _kale_block5 = '''\n    model = build_model(vocab_size)\n\
        \    '''\n\n    _kale_block6 = '''\n    model.summary()\n    '''\n\n    _kale_block7\
        \ = '''\n    class MeanColumnwiseRMSE(tf.keras.losses.Loss):\n        def\
        \ __init__(self, name='MeanColumnwiseRMSE'):\n            super().__init__(name=name)\n\
        \n        def call(self, y_true, y_pred):\n            colwise_mse = tf.reduce_mean(tf.square(y_true\
        \ - y_pred), axis=1)\n            return tf.reduce_mean(tf.sqrt(colwise_mse),\
        \ axis=1)\n    '''\n\n    _kale_block8 = '''\n    model.compile(tf.optimizers.Adam(learning_rate=float(LR)),\
        \ loss=MeanColumnwiseRMSE())\n    '''\n\n    _kale_block9 = '''\n    history\
        \ = model.fit(np.array(x_train), np.array(y_train), \n                   \
        \     batch_size=int(BATCH_SIZE), epochs=int(EPOCHS))\n    '''\n\n    _kale_block10\
        \ = '''\n    # history.history.get(\"val_loss\")\n    '''\n\n    _kale_data_saving_block\
        \ = '''\n    # -----------------------DATA SAVING START---------------------------------\n\
        \    from kale import marshal as _kale_marshal\n    _kale_marshal.set_data_dir(\"\
        /marshal\")\n    _kale_marshal.save(build_model, \"build_model\")\n    _kale_marshal.save(gru_layer,\
        \ \"gru_layer\")\n    _kale_marshal.save(lstm_layer, \"lstm_layer\")\n   \
        \ _kale_marshal.save(model, \"model\")\n    _kale_marshal.save(vocab_size,\
        \ \"vocab_size\")\n    # -----------------------DATA SAVING END-----------------------------------\n\
        \    '''\n\n    # run the code blocks inside a jupyter kernel\n    from kale.common.jputils\
        \ import run_code as _kale_run_code\n    from kale.common.kfputils import\
        \ \\\n        update_uimetadata as _kale_update_uimetadata\n    _kale_blocks\
        \ = (_kale_pipeline_parameters_block, _kale_data_loading_block,\n        \
        \            _kale_block1,\n                    _kale_block2,\n          \
        \          _kale_block3,\n                    _kale_block4,\n            \
        \        _kale_block5,\n                    _kale_block6,\n              \
        \      _kale_block7,\n                    _kale_block8,\n                \
        \    _kale_block9,\n                    _kale_block10,\n                 \
        \   _kale_data_saving_block)\n    _kale_html_artifact = _kale_run_code(_kale_blocks)\n\
        \    with open(\"/model_training.html\", \"w\") as f:\n        f.write(_kale_html_artifact)\n\
        \    _kale_update_uimetadata('model_training')\n\n    _kale_mlmdutils.call(\"\
        mark_execution_complete\")\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Model\
        \ training', description='')\n_parser.add_argument(\"--BATCH-SIZE\", dest=\"\
        BATCH_SIZE\", type=int, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"\
        --DROPOUT\", dest=\"DROPOUT\", type=float, required=True, default=argparse.SUPPRESS)\n\
        _parser.add_argument(\"--EMBED-DIM\", dest=\"EMBED_DIM\", type=int, required=True,\
        \ default=argparse.SUPPRESS)\n_parser.add_argument(\"--EPOCHS\", dest=\"EPOCHS\"\
        , type=int, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"\
        --HIDDEN-DIM\", dest=\"HIDDEN_DIM\", type=int, required=True, default=argparse.SUPPRESS)\n\
        _parser.add_argument(\"--LR\", dest=\"LR\", type=float, required=True, default=argparse.SUPPRESS)\n\
        _parser.add_argument(\"--SP-DROPOUT\", dest=\"SP_DROPOUT\", type=float, required=True,\
        \ default=argparse.SUPPRESS)\n_parser.add_argument(\"--TRAIN-SEQUENCE-LENGTH\"\
        , dest=\"TRAIN_SEQUENCE_LENGTH\", type=int, required=True, default=argparse.SUPPRESS)\n\
        _parsed_args = vars(_parser.parse_args())\n\n_outputs = model_training(**_parsed_args)\n"
      image: ' ali-art.hfinside.com/dev-v/app/jupyter-kale:20211116'
      securityContext: {runAsUser: 0}
      volumeMounts:
      - {mountPath: /marshal, name: kale-marshal-volume}
      workingDir: /home/jovyan/openvaccine-kaggle-competition
    inputs:
      parameters:
      - {name: BATCH_SIZE}
      - {name: DROPOUT}
      - {name: EMBED_DIM}
      - {name: EPOCHS}
      - {name: HIDDEN_DIM}
      - {name: LR}
      - {name: SP_DROPOUT}
      - {name: TRAIN_SEQUENCE_LENGTH}
      - {name: kale-marshal-volume-name}
    outputs:
      artifacts:
      - {name: mlpipeline-ui-metadata, path: /tmp/mlpipeline-ui-metadata.json}
      - {name: model_training, path: /model_training.html}
    metadata:
      annotations: {kubeflow-kale.org/dependent-templates: '["preprocess-data", "kale-marshal-volume"]',
        kubeflow-kale.org/volume-name-parameters: '["kale-marshal-volume-name"]',
        pipelines.kubeflow.org/component_spec: '{"implementation": {"container": {"args":
          ["--BATCH-SIZE", {"inputValue": "BATCH_SIZE"}, "--DROPOUT", {"inputValue":
          "DROPOUT"}, "--EMBED-DIM", {"inputValue": "EMBED_DIM"}, "--EPOCHS", {"inputValue":
          "EPOCHS"}, "--HIDDEN-DIM", {"inputValue": "HIDDEN_DIM"}, "--LR", {"inputValue":
          "LR"}, "--SP-DROPOUT", {"inputValue": "SP_DROPOUT"}, "--TRAIN-SEQUENCE-LENGTH",
          {"inputValue": "TRAIN_SEQUENCE_LENGTH"}], "command": ["sh", "-ec", "program_path=$(mktemp)\nprintf
          \"%s\" \"$0\" > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n",
          "def model_training(BATCH_SIZE, DROPOUT, EMBED_DIM, EPOCHS, HIDDEN_DIM,
          LR, SP_DROPOUT, TRAIN_SEQUENCE_LENGTH):\n    _kale_pipeline_parameters_block
          = ''''''\n    BATCH_SIZE = {}\n    DROPOUT = {}\n    EMBED_DIM = {}\n    EPOCHS
          = {}\n    HIDDEN_DIM = {}\n    LR = {}\n    SP_DROPOUT = {}\n    TRAIN_SEQUENCE_LENGTH
          = {}\n    ''''''.format(BATCH_SIZE, DROPOUT, EMBED_DIM, EPOCHS, HIDDEN_DIM,
          LR, SP_DROPOUT, TRAIN_SEQUENCE_LENGTH)\n\n    from kale.common import mlmdutils
          as _kale_mlmdutils\n    _kale_mlmdutils.init_metadata()\n\n    _kale_data_loading_block
          = ''''''\n    # -----------------------DATA LOADING START--------------------------------\n    from
          kale import marshal as _kale_marshal\n    _kale_marshal.set_data_dir(\"/marshal\")\n    vocab_size
          = _kale_marshal.load(\"vocab_size\")\n    x_train = _kale_marshal.load(\"x_train\")\n    y_train
          = _kale_marshal.load(\"y_train\")\n    # -----------------------DATA LOADING
          END----------------------------------\n    ''''''\n\n    _kale_block1 =
          ''''''\n    import json\n    import numpy as np\n    import pandas as pd\n    import
          tensorflow as tf\n    import os \n\n    from tensorflow.keras.preprocessing.text
          import Tokenizer\n    ''''''\n\n    _kale_block2 = ''''''\n    def gru_layer(hidden_dim,
          dropout):\n        return tf.keras.layers.Bidirectional(\n             tf.keras.layers.GRU(hidden_dim,
          dropout=dropout, return_sequences=True, kernel_initializer = ''orthogonal'')\n        )\n    ''''''\n\n    _kale_block3
          = ''''''\n    def lstm_layer(hidden_dim, dropout):\n        return tf.keras.layers.Bidirectional(\n            tf.keras.layers.LSTM(hidden_dim,
          dropout=dropout, return_sequences=True, kernel_initializer = ''orthogonal'')\n        )\n    ''''''\n\n    _kale_block4
          = ''''''\n    def build_model(vocab_size, seq_length=int(TRAIN_SEQUENCE_LENGTH),
          pred_len=68,\n                    embed_dim=int(EMBED_DIM),\n                    hidden_dim=int(HIDDEN_DIM),
          dropout=float(DROPOUT), sp_dropout=float(SP_DROPOUT)):\n        inputs =
          tf.keras.layers.Input(shape=(seq_length, 3))\n\n        embed = tf.keras.layers.Embedding(input_dim=vocab_size,
          output_dim=embed_dim)(inputs)\n\n        reshaped = tf.reshape(\n            embed,
          shape=(-1, embed.shape[1],  embed.shape[2] * embed.shape[3])\n        )\n\n        hidden
          = tf.keras.layers.SpatialDropout1D(sp_dropout)(reshaped)\n\n        hidden
          = gru_layer(hidden_dim, dropout)(hidden)\n        hidden = lstm_layer(hidden_dim,
          dropout)(hidden)\n\n        truncated = hidden[:, :pred_len]\n\n        out
          = tf.keras.layers.Dense(5, activation=\"linear\")(truncated)\n\n        model
          = tf.keras.Model(inputs=inputs, outputs=out)\n\n        return model\n    ''''''\n\n    _kale_block5
          = ''''''\n    model = build_model(vocab_size)\n    ''''''\n\n    _kale_block6
          = ''''''\n    model.summary()\n    ''''''\n\n    _kale_block7 = ''''''\n    class
          MeanColumnwiseRMSE(tf.keras.losses.Loss):\n        def __init__(self, name=''MeanColumnwiseRMSE''):\n            super().__init__(name=name)\n\n        def
          call(self, y_true, y_pred):\n            colwise_mse = tf.reduce_mean(tf.square(y_true
          - y_pred), axis=1)\n            return tf.reduce_mean(tf.sqrt(colwise_mse),
          axis=1)\n    ''''''\n\n    _kale_block8 = ''''''\n    model.compile(tf.optimizers.Adam(learning_rate=float(LR)),
          loss=MeanColumnwiseRMSE())\n    ''''''\n\n    _kale_block9 = ''''''\n    history
          = model.fit(np.array(x_train), np.array(y_train), \n                        batch_size=int(BATCH_SIZE),
          epochs=int(EPOCHS))\n    ''''''\n\n    _kale_block10 = ''''''\n    # history.history.get(\"val_loss\")\n    ''''''\n\n    _kale_data_saving_block
          = ''''''\n    # -----------------------DATA SAVING START---------------------------------\n    from
          kale import marshal as _kale_marshal\n    _kale_marshal.set_data_dir(\"/marshal\")\n    _kale_marshal.save(build_model,
          \"build_model\")\n    _kale_marshal.save(gru_layer, \"gru_layer\")\n    _kale_marshal.save(lstm_layer,
          \"lstm_layer\")\n    _kale_marshal.save(model, \"model\")\n    _kale_marshal.save(vocab_size,
          \"vocab_size\")\n    # -----------------------DATA SAVING END-----------------------------------\n    ''''''\n\n    #
          run the code blocks inside a jupyter kernel\n    from kale.common.jputils
          import run_code as _kale_run_code\n    from kale.common.kfputils import
          \\\n        update_uimetadata as _kale_update_uimetadata\n    _kale_blocks
          = (_kale_pipeline_parameters_block, _kale_data_loading_block,\n                    _kale_block1,\n                    _kale_block2,\n                    _kale_block3,\n                    _kale_block4,\n                    _kale_block5,\n                    _kale_block6,\n                    _kale_block7,\n                    _kale_block8,\n                    _kale_block9,\n                    _kale_block10,\n                    _kale_data_saving_block)\n    _kale_html_artifact
          = _kale_run_code(_kale_blocks)\n    with open(\"/model_training.html\",
          \"w\") as f:\n        f.write(_kale_html_artifact)\n    _kale_update_uimetadata(''model_training'')\n\n    _kale_mlmdutils.call(\"mark_execution_complete\")\n\nimport
          argparse\n_parser = argparse.ArgumentParser(prog=''Model training'', description='''')\n_parser.add_argument(\"--BATCH-SIZE\",
          dest=\"BATCH_SIZE\", type=int, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--DROPOUT\",
          dest=\"DROPOUT\", type=float, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--EMBED-DIM\",
          dest=\"EMBED_DIM\", type=int, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--EPOCHS\",
          dest=\"EPOCHS\", type=int, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--HIDDEN-DIM\",
          dest=\"HIDDEN_DIM\", type=int, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--LR\",
          dest=\"LR\", type=float, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--SP-DROPOUT\",
          dest=\"SP_DROPOUT\", type=float, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--TRAIN-SEQUENCE-LENGTH\",
          dest=\"TRAIN_SEQUENCE_LENGTH\", type=int, required=True, default=argparse.SUPPRESS)\n_parsed_args
          = vars(_parser.parse_args())\n\n_outputs = model_training(**_parsed_args)\n"],
          "image": " ali-art.hfinside.com/dev-v/app/jupyter-kale:20211116"}}, "inputs":
          [{"name": "BATCH_SIZE", "type": "Integer"}, {"name": "DROPOUT", "type":
          "Float"}, {"name": "EMBED_DIM", "type": "Integer"}, {"name": "EPOCHS", "type":
          "Integer"}, {"name": "HIDDEN_DIM", "type": "Integer"}, {"name": "LR", "type":
          "Float"}, {"name": "SP_DROPOUT", "type": "Float"}, {"name": "TRAIN_SEQUENCE_LENGTH",
          "type": "Integer"}], "name": "Model training"}', pipelines.kubeflow.org/component_ref: '{}',
        pipelines.kubeflow.org/arguments.parameters: '{"BATCH_SIZE": "{{inputs.parameters.BATCH_SIZE}}",
          "DROPOUT": "{{inputs.parameters.DROPOUT}}", "EMBED_DIM": "{{inputs.parameters.EMBED_DIM}}",
          "EPOCHS": "{{inputs.parameters.EPOCHS}}", "HIDDEN_DIM": "{{inputs.parameters.HIDDEN_DIM}}",
          "LR": "{{inputs.parameters.LR}}", "SP_DROPOUT": "{{inputs.parameters.SP_DROPOUT}}",
          "TRAIN_SEQUENCE_LENGTH": "{{inputs.parameters.TRAIN_SEQUENCE_LENGTH}}"}'}
      labels:
        access-ml-pipeline: "true"
        pipelines.kubeflow.org/metadata_written: "true"
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.2
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "false"
    volumes:
    - name: kale-marshal-volume
      persistentVolumeClaim: {claimName: '{{inputs.parameters.kale-marshal-volume-name}}'}
  - name: open-vaccine-123456
    inputs:
      parameters:
      - {name: BATCH_SIZE}
      - {name: DROPOUT}
      - {name: EMBED_DIM}
      - {name: EPOCHS}
      - {name: HIDDEN_DIM}
      - {name: LR}
      - {name: SP_DROPOUT}
      - {name: TRAIN_SEQUENCE_LENGTH}
    dag:
      tasks:
      - {name: kale-marshal-volume, template: kale-marshal-volume}
      - name: load-data
        template: load-data
        dependencies: [kale-marshal-volume]
        arguments:
          parameters:
          - {name: kale-marshal-volume-name, value: '{{tasks.kale-marshal-volume.outputs.parameters.kale-marshal-volume-name}}'}
      - name: model-evaluation
        template: model-evaluation
        dependencies: [kale-marshal-volume, model-training]
        arguments:
          parameters:
          - {name: DROPOUT, value: '{{inputs.parameters.DROPOUT}}'}
          - {name: EMBED_DIM, value: '{{inputs.parameters.EMBED_DIM}}'}
          - {name: HIDDEN_DIM, value: '{{inputs.parameters.HIDDEN_DIM}}'}
          - {name: SP_DROPOUT, value: '{{inputs.parameters.SP_DROPOUT}}'}
          - {name: TRAIN_SEQUENCE_LENGTH, value: '{{inputs.parameters.TRAIN_SEQUENCE_LENGTH}}'}
          - {name: kale-marshal-volume-name, value: '{{tasks.kale-marshal-volume.outputs.parameters.kale-marshal-volume-name}}'}
      - name: model-training
        template: model-training
        dependencies: [kale-marshal-volume, preprocess-data]
        arguments:
          parameters:
          - {name: BATCH_SIZE, value: '{{inputs.parameters.BATCH_SIZE}}'}
          - {name: DROPOUT, value: '{{inputs.parameters.DROPOUT}}'}
          - {name: EMBED_DIM, value: '{{inputs.parameters.EMBED_DIM}}'}
          - {name: EPOCHS, value: '{{inputs.parameters.EPOCHS}}'}
          - {name: HIDDEN_DIM, value: '{{inputs.parameters.HIDDEN_DIM}}'}
          - {name: LR, value: '{{inputs.parameters.LR}}'}
          - {name: SP_DROPOUT, value: '{{inputs.parameters.SP_DROPOUT}}'}
          - {name: TRAIN_SEQUENCE_LENGTH, value: '{{inputs.parameters.TRAIN_SEQUENCE_LENGTH}}'}
          - {name: kale-marshal-volume-name, value: '{{tasks.kale-marshal-volume.outputs.parameters.kale-marshal-volume-name}}'}
      - name: preprocess-data
        template: preprocess-data
        dependencies: [kale-marshal-volume, load-data]
        arguments:
          parameters:
          - {name: kale-marshal-volume-name, value: '{{tasks.kale-marshal-volume.outputs.parameters.kale-marshal-volume-name}}'}
  - name: preprocess-data
    container:
      args: []
      command:
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - "def preprocess_data():\n    from kale.common import mlmdutils as _kale_mlmdutils\n\
        \    _kale_mlmdutils.init_metadata()\n\n    _kale_data_loading_block = '''\n\
        \    # -----------------------DATA LOADING START--------------------------------\n\
        \    from kale import marshal as _kale_marshal\n    _kale_marshal.set_data_dir(\"\
        /marshal\")\n    test_df = _kale_marshal.load(\"test_df\")\n    train_df =\
        \ _kale_marshal.load(\"train_df\")\n    # -----------------------DATA LOADING\
        \ END----------------------------------\n    '''\n\n    _kale_block1 = '''\n\
        \    import json\n    import numpy as np\n    import pandas as pd\n    import\
        \ tensorflow as tf\n    import os \n\n    from tensorflow.keras.preprocessing.text\
        \ import Tokenizer\n    '''\n\n    _kale_block2 = '''\n    symbols = \"().ACGUBEHIMSX\"\
        \n    feat_cols = [\"sequence\", \"structure\", \"predicted_loop_type\"]\n\
        \    target_cols = [\"reactivity\", \"deg_Mg_pH10\", \"deg_Mg_50C\", \"deg_pH10\"\
        , \"deg_50C\"]\n    error_cols = [\"reactivity_error\", \"deg_error_Mg_pH10\"\
        , \"deg_error_Mg_50C\", \"deg_error_pH10\", \"deg_error_50C\"]\n    '''\n\n\
        \    _kale_block3 = '''\n    tokenizer = Tokenizer(char_level=True, filters=\"\
        \")\n    tokenizer.fit_on_texts(symbols)\n    '''\n\n    _kale_block4 = '''\n\
        \    # get the number of elements in the vocabulary\n    vocab_size = len(tokenizer.word_index)\
        \ + 1\n    '''\n\n    _kale_block5 = '''\n    def process_features(example):\n\
        \        sequence_sentences = example[0]\n        structure_sentences = example[1]\n\
        \        loop_sentences = example[2]\n\n        # transform character sequences\
        \ into number sequences\n        sequence_tokens = np.array(\n           \
        \ tokenizer.texts_to_sequences(sequence_sentences)\n        )\n        structure_tokens\
        \ = np.array(\n            tokenizer.texts_to_sequences(structure_sentences)\n\
        \        )\n        loop_tokens = np.array(\n            tokenizer.texts_to_sequences(loop_sentences)\n\
        \        )\n\n        # concatenate the tokenized sequences\n        sequences\
        \ = np.stack(\n            (sequence_tokens, structure_tokens, loop_tokens),\n\
        \            axis=1\n        )\n        sequences = np.transpose(sequences,\
        \ (2, 0, 1))\n\n        prepared = sequences.tolist()\n\n        return prepared[0]\n\
        \    '''\n\n    _kale_block6 = '''\n    def process_labels(df):\n        df\
        \ = df.copy()\n\n        labels = np.array(df[target_cols].values.tolist())\n\
        \        labels = np.transpose(labels, (0, 2, 1))\n\n        return labels\n\
        \    '''\n\n    _kale_block7 = '''\n    public_test_df = test_df.query(\"\
        seq_length == 107\")\n    private_test_df = test_df.query(\"seq_length ==\
        \ 130\")\n    '''\n\n    _kale_block8 = '''\n    x_train = [process_features(row.tolist())\
        \ for _, row in train_df[feat_cols].iterrows()]\n    y_train = process_labels(train_df)\n\
        \n    unprocessed_x_public_test = [row.tolist() for _, row in public_test_df[feat_cols].iterrows()]\n\
        \    unprocessed_x_private_test = [row.tolist() for _, row in private_test_df[feat_cols].iterrows()]\n\
        \    '''\n\n    _kale_data_saving_block = '''\n    # -----------------------DATA\
        \ SAVING START---------------------------------\n    from kale import marshal\
        \ as _kale_marshal\n    _kale_marshal.set_data_dir(\"/marshal\")\n    _kale_marshal.save(process_features,\
        \ \"process_features\")\n    _kale_marshal.save(tokenizer, \"tokenizer\")\n\
        \    _kale_marshal.save(unprocessed_x_private_test, \"unprocessed_x_private_test\"\
        )\n    _kale_marshal.save(unprocessed_x_public_test, \"unprocessed_x_public_test\"\
        )\n    _kale_marshal.save(vocab_size, \"vocab_size\")\n    _kale_marshal.save(x_train,\
        \ \"x_train\")\n    _kale_marshal.save(y_train, \"y_train\")\n    # -----------------------DATA\
        \ SAVING END-----------------------------------\n    '''\n\n    # run the\
        \ code blocks inside a jupyter kernel\n    from kale.common.jputils import\
        \ run_code as _kale_run_code\n    from kale.common.kfputils import \\\n  \
        \      update_uimetadata as _kale_update_uimetadata\n    _kale_blocks = (_kale_data_loading_block,\n\
        \                    _kale_block1,\n                    _kale_block2,\n  \
        \                  _kale_block3,\n                    _kale_block4,\n    \
        \                _kale_block5,\n                    _kale_block6,\n      \
        \              _kale_block7,\n                    _kale_block8,\n        \
        \            _kale_data_saving_block)\n    _kale_html_artifact = _kale_run_code(_kale_blocks)\n\
        \    with open(\"/preprocess_data.html\", \"w\") as f:\n        f.write(_kale_html_artifact)\n\
        \    _kale_update_uimetadata('preprocess_data')\n\n    _kale_mlmdutils.call(\"\
        mark_execution_complete\")\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Preprocess\
        \ data', description='')\n_parsed_args = vars(_parser.parse_args())\n\n_outputs\
        \ = preprocess_data(**_parsed_args)\n"
      image: ' ali-art.hfinside.com/dev-v/app/jupyter-kale:20211116'
      securityContext: {runAsUser: 0}
      volumeMounts:
      - {mountPath: /marshal, name: kale-marshal-volume}
      workingDir: /home/jovyan/openvaccine-kaggle-competition
    inputs:
      parameters:
      - {name: kale-marshal-volume-name}
    outputs:
      artifacts:
      - {name: mlpipeline-ui-metadata, path: /tmp/mlpipeline-ui-metadata.json}
      - {name: preprocess_data, path: /preprocess_data.html}
    metadata:
      annotations: {kubeflow-kale.org/dependent-templates: '["load-data", "kale-marshal-volume"]',
        kubeflow-kale.org/volume-name-parameters: '["kale-marshal-volume-name"]',
        pipelines.kubeflow.org/component_spec: '{"implementation": {"container": {"args":
          [], "command": ["sh", "-ec", "program_path=$(mktemp)\nprintf \"%s\" \"$0\"
          > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n", "def preprocess_data():\n    from
          kale.common import mlmdutils as _kale_mlmdutils\n    _kale_mlmdutils.init_metadata()\n\n    _kale_data_loading_block
          = ''''''\n    # -----------------------DATA LOADING START--------------------------------\n    from
          kale import marshal as _kale_marshal\n    _kale_marshal.set_data_dir(\"/marshal\")\n    test_df
          = _kale_marshal.load(\"test_df\")\n    train_df = _kale_marshal.load(\"train_df\")\n    #
          -----------------------DATA LOADING END----------------------------------\n    ''''''\n\n    _kale_block1
          = ''''''\n    import json\n    import numpy as np\n    import pandas as
          pd\n    import tensorflow as tf\n    import os \n\n    from tensorflow.keras.preprocessing.text
          import Tokenizer\n    ''''''\n\n    _kale_block2 = ''''''\n    symbols =
          \"().ACGUBEHIMSX\"\n    feat_cols = [\"sequence\", \"structure\", \"predicted_loop_type\"]\n    target_cols
          = [\"reactivity\", \"deg_Mg_pH10\", \"deg_Mg_50C\", \"deg_pH10\", \"deg_50C\"]\n    error_cols
          = [\"reactivity_error\", \"deg_error_Mg_pH10\", \"deg_error_Mg_50C\", \"deg_error_pH10\",
          \"deg_error_50C\"]\n    ''''''\n\n    _kale_block3 = ''''''\n    tokenizer
          = Tokenizer(char_level=True, filters=\"\")\n    tokenizer.fit_on_texts(symbols)\n    ''''''\n\n    _kale_block4
          = ''''''\n    # get the number of elements in the vocabulary\n    vocab_size
          = len(tokenizer.word_index) + 1\n    ''''''\n\n    _kale_block5 = ''''''\n    def
          process_features(example):\n        sequence_sentences = example[0]\n        structure_sentences
          = example[1]\n        loop_sentences = example[2]\n\n        # transform
          character sequences into number sequences\n        sequence_tokens = np.array(\n            tokenizer.texts_to_sequences(sequence_sentences)\n        )\n        structure_tokens
          = np.array(\n            tokenizer.texts_to_sequences(structure_sentences)\n        )\n        loop_tokens
          = np.array(\n            tokenizer.texts_to_sequences(loop_sentences)\n        )\n\n        #
          concatenate the tokenized sequences\n        sequences = np.stack(\n            (sequence_tokens,
          structure_tokens, loop_tokens),\n            axis=1\n        )\n        sequences
          = np.transpose(sequences, (2, 0, 1))\n\n        prepared = sequences.tolist()\n\n        return
          prepared[0]\n    ''''''\n\n    _kale_block6 = ''''''\n    def process_labels(df):\n        df
          = df.copy()\n\n        labels = np.array(df[target_cols].values.tolist())\n        labels
          = np.transpose(labels, (0, 2, 1))\n\n        return labels\n    ''''''\n\n    _kale_block7
          = ''''''\n    public_test_df = test_df.query(\"seq_length == 107\")\n    private_test_df
          = test_df.query(\"seq_length == 130\")\n    ''''''\n\n    _kale_block8 =
          ''''''\n    x_train = [process_features(row.tolist()) for _, row in train_df[feat_cols].iterrows()]\n    y_train
          = process_labels(train_df)\n\n    unprocessed_x_public_test = [row.tolist()
          for _, row in public_test_df[feat_cols].iterrows()]\n    unprocessed_x_private_test
          = [row.tolist() for _, row in private_test_df[feat_cols].iterrows()]\n    ''''''\n\n    _kale_data_saving_block
          = ''''''\n    # -----------------------DATA SAVING START---------------------------------\n    from
          kale import marshal as _kale_marshal\n    _kale_marshal.set_data_dir(\"/marshal\")\n    _kale_marshal.save(process_features,
          \"process_features\")\n    _kale_marshal.save(tokenizer, \"tokenizer\")\n    _kale_marshal.save(unprocessed_x_private_test,
          \"unprocessed_x_private_test\")\n    _kale_marshal.save(unprocessed_x_public_test,
          \"unprocessed_x_public_test\")\n    _kale_marshal.save(vocab_size, \"vocab_size\")\n    _kale_marshal.save(x_train,
          \"x_train\")\n    _kale_marshal.save(y_train, \"y_train\")\n    # -----------------------DATA
          SAVING END-----------------------------------\n    ''''''\n\n    # run the
          code blocks inside a jupyter kernel\n    from kale.common.jputils import
          run_code as _kale_run_code\n    from kale.common.kfputils import \\\n        update_uimetadata
          as _kale_update_uimetadata\n    _kale_blocks = (_kale_data_loading_block,\n                    _kale_block1,\n                    _kale_block2,\n                    _kale_block3,\n                    _kale_block4,\n                    _kale_block5,\n                    _kale_block6,\n                    _kale_block7,\n                    _kale_block8,\n                    _kale_data_saving_block)\n    _kale_html_artifact
          = _kale_run_code(_kale_blocks)\n    with open(\"/preprocess_data.html\",
          \"w\") as f:\n        f.write(_kale_html_artifact)\n    _kale_update_uimetadata(''preprocess_data'')\n\n    _kale_mlmdutils.call(\"mark_execution_complete\")\n\nimport
          argparse\n_parser = argparse.ArgumentParser(prog=''Preprocess data'', description='''')\n_parsed_args
          = vars(_parser.parse_args())\n\n_outputs = preprocess_data(**_parsed_args)\n"],
          "image": " ali-art.hfinside.com/dev-v/app/jupyter-kale:20211116"}}, "name":
          "Preprocess data"}', pipelines.kubeflow.org/component_ref: '{}'}
      labels:
        access-ml-pipeline: "true"
        pipelines.kubeflow.org/metadata_written: "true"
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.2
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "false"
    volumes:
    - name: kale-marshal-volume
      persistentVolumeClaim: {claimName: '{{inputs.parameters.kale-marshal-volume-name}}'}
  arguments:
    parameters:
    - {name: BATCH_SIZE, value: '64'}
    - {name: DROPOUT, value: '0.5'}
    - {name: EMBED_DIM, value: '100'}
    - {name: EPOCHS, value: '10'}
    - {name: HIDDEN_DIM, value: '128'}
    - {name: LR, value: '0.001'}
    - {name: SP_DROPOUT, value: '0.3'}
    - {name: TRAIN_SEQUENCE_LENGTH, value: '107'}
  serviceAccountName: pipeline-runner

